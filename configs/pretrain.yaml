# Pretrain datasets
train_file: 'F:/.python/NLP/Datasets/ROCO/train/data.csv'
image_root: 'F:/.python/NLP/Datasets/ROCO/train/images'

text_config: 'bert-base-uncased'
bert_config: 'configs/config_bert.json'


# vision_deit_path: '/mnt/sda/lpf/weights/pre_training/vision_pth/deit_base_patch16_224.pth'
vit_mae_pretrain_path: 'F:/.python/NLP/Compact-MUMC/models/saved/vit/deit_base_patch16_224-b5f2ef4d.pth'

image_res: 256
vision_width: 768
embed_dim: 256  # 193 # 129 # 256
batch_size: 64
temp: 0.07
mlm_probability: 0.15
queue_size: 65536
momentum: 0.995
alpha: 0.4

# optimizer
weight_decay: 0.05
power_decay: -0.1

init_lr: 1e-5
min_lr: 1e-6
warmup_lr: 1e-6
lr_decay_rate: 0.9
max_epoch: 20
warmup_steps: 3000